<!DOCTYPE html>
<html lang="en">
<head>
        <title>charlesreid1</title>
        <meta charset="utf-8" />

        <!--
        CSS styles
        -->
        <link href="http://localhost:8000/theme/css/bootstrap.css"       rel="stylesheet" type="text/css">
        <link href="http://localhost:8000/theme/css/slate.css"              rel="stylesheet" type="text/css">
        <link href="http://localhost:8000/theme/css/font-awesome.css"       rel="stylesheet" type="text/css"/>
        <link href="http://localhost:8000/theme/css/pygment-solarized.css"  rel="stylesheet" type="text/css"/>

        <!--
        my CSS styles
        -->
        <link href="http://localhost:8000/theme/css/main.css"            rel="stylesheet" type="text/css">
        <link href="http://localhost:8000/theme/css/dox.css"             rel="stylesheet" type="text/css">


        <!--
        include Angular first
        -->
        <script type="text/javascript" src="http://localhost:8000/theme/js/angular-1.3.15.js"></script>
        <script type="text/javascript" src="http://localhost:8000/theme/js/skrollr-0.6.29.js"></script>
        <script type="text/javascript" src="http://localhost:8000/theme/js/d3-3.5.5.js"></script>

        <!--
        this seems like a bad idea.
        but if I don't put jquery first, I get errors about unrecognized $s.
        -->
        <script type="text/javascript" src="http://localhost:8000/theme/js/jquery-1.11.2.js"></script>

</head>
<body id="index">
<nav class="navbar navbar-default">
    <div class="container-fluid">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span> 
            </button>
            <a href="https://charlesreid1.github.io" class="navbar-brand">charlesreid1.github.io</a>
        </div>
        <div>
            <div class="collapse navbar-collapse" id="myNavbar">
                <ul class="nav navbar-nav">

                    <li>
                        <a href="https://charlesreid1.com/wiki">Wiki</a>
                    </li>
                    <li>
                        <a href="https://git.charlesreid1.com/explore">Git</a>
                    </li>
                    <li>
                        <a href="http://spotify.charlesreid1.com">Music</a>
                    </li>
                    <li>
                        <a href="https://charlesreid1.com/life">Life</a>
                    </li>
                    <li>
                        <a href="https://charlesreid1.github.io">Blog</a>
                    </li>
                    <li>
                        <a href="https://charlesreid1.com/about">About Me</a>
                    </li>

                </ul>
            </div>
        </div>
    </div>
</nav>



<div class="container">

<header>
<div class="row">


    <div class="col-md-12">
        <div class="headtext" style="text-align: center;">
            <h1><b>
                Building Snakemake Command Line Wrappers for Kubernetes Workflows
            </b></h1>
        
            <p class="lead">
                Posted 
                <time datetime="2019-01-28T20:00:00-08:00" pubdate>Monday 01/28/2019</time>
                in 
                <a href="http://localhost:8000/category/snakemake.html">Snakemake</a>
                </p>
            <p>
            <span style="font-size: 14px">
                <a href="http://localhost:8000/building-snakemake-command-line-wrappers-for-kubernetes-workflows.html">permalink</a>
            </span>
            </p>
        </div>

    </div>

</div>
</header>


<div class="v50"></div>


<div class="row">
    <div class="col-md-12" style="text-align: left;">

        <div class="entry-content"><p><strong>NOTE:</strong> These ideas are implemented in the repository
<a href="https://github.com/charlesreid/2019-snakemake-byok8s">charlesreid1/2019-snakemake-byok8s</a>.</p>
<div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#recap-workflows-as-executables">Recap: Workflows as Executables</a><ul>
<li><a href="#2018-snakemake-cli">2018-snakemake-cli</a></li>
<li><a href="#2019-snakemake-cli">2019-snakemake-cli</a></li>
<li><a href="#2019-snakemake-byok8s">2019-snakemake-byok8s</a></li>
</ul>
</li>
<li><a href="#overview-of-2019-snakemake-byok8s">Overview of 2019-snakemake-byok8s</a><ul>
<li><a href="#cloud-scale-kubernetes-k8s">Cloud + Scale = Kubernetes (k8s)</a></li>
<li><a href="#snakemake-k8s-support">Snakemake k8s Support</a></li>
</ul>
</li>
<li><a href="#modifying-the-cli">Modifying the CLI</a><ul>
<li><a href="#namespaces">Namespaces</a></li>
<li><a href="#adding-flags">Adding flags</a></li>
</ul>
</li>
<li><a href="#local-kubernetes-clusters-with-minikube">Local Kubernetes Clusters with Minikube</a><ul>
<li><a href="#what-is-minikube">What is minikube?</a></li>
<li><a href="#aws">AWS</a><ul>
<li><a href="#installing-python-prerequisites">Installing Python Prerequisites</a></li>
<li><a href="#installing-byok8s">Installing byok8s</a></li>
<li><a href="#starting-a-k8s-cluster-with-minikube">Starting a k8s cluster with minikube</a></li>
</ul>
</li>
<li><a href="#fixing-dns-issues-with-aws">Fixing DNS issues with AWS</a><ul>
<li><a href="#the-problem">The Problem</a></li>
<li><a href="#the-fix">The Fix</a></li>
</ul>
</li>
<li><a href="#aws-byok8s-workflow">AWS + byok8s Workflow</a></li>
<li><a href="#travis">Travis</a></li>
<li><a href="#travisyml">.travis.yml</a></li>
</ul>
</li>
<li><a href="#end-product-byok8s">End Product: byok8s</a></li>
<li><a href="#documentation">Documentation</a></li>
<li><a href="#next-steps">Next Steps</a></li>
</ul>
</div>
<h1 id="recap-workflows-as-executables">Recap: Workflows as Executables</h1>
<p>In our previous blog post, <a href="https://charlesreid1.github.io/building-snakemake-command-line-wrappers.html">Building Snakemake Command Line Wrappers</a>,
we covered some approaches to making Snakemake
workflows into executables that can be run as
command line utilities.</p>
<p>In this post, we extend those ideas to Snakemake workflows
that run on Kubernetes clusters.</p>
<h2 id="2018-snakemake-cli">2018-snakemake-cli</h2>
<p>To recap, back in March 2018 Titus Brown wrote a blog post titled
<a href="http://ivory.idyll.org/blog/2018-workflows-applications.html">Pydoit, snakemake, and workflows-as-applications</a>
in which he implemented a proof-of-concept command
line utility wrapping the Snakemake API to create
an executable Snakemake workflow.</p>
<p>The end result was a command line utility that could
be run like so:</p>
<div class="highlight"><pre><span></span>./run &lt;workflow-config&gt; &lt;workflow-params&gt;
</pre></div>


<p>Relevant code is in <a href="https://github.com/ctb/2018-snakemake-cli">ctb/2018-snakemake-cli</a>.</p>
<p><a name="2019"></a></p>
<h2 id="2019-snakemake-cli">2019-snakemake-cli</h2>
<p>In our previous blog post, <a href="https://charlesreid1.github.io/building-snakemake-command-line-wrappers.html">Building Snakemake Command Line Wrappers</a>,
we extended this idea to create a bundled executable
command line utility that could be installed with
<code>setup.py</code> and run from a working directory. We also
demonstrated a method of writing tests for the 
Snakemake workflow and running those tests with
Travis CI.</p>
<p>We packaged the Snakefile with the command line utility,
but the approach is flexible and can be modified to
use a user-provided Snakemake workflow or Snakefile.</p>
<p>The end result was a command line utility called
<code>bananas</code> that could be installed and run like
the <code>run</code> wrapper above:</p>
<div class="highlight"><pre><span></span>bananas &lt;workflow-config&gt; &lt;workflow-params&gt;
</pre></div>


<p>Relevant code is in <a href="https://github.com/charlesreid1/2019-snakemake-cli">charlesreid1/2019-snakemake-cli</a>.</p>
<p><a name="byok8s"></a></p>
<h2 id="2019-snakemake-byok8s">2019-snakemake-byok8s</h2>
<p>The next logical step in bundling workflows was to take
advantage of Snakemake's ability to run workflows across
distributed systems.</p>
<p>Specifically, we wanted to modify the command line utility
above to run the workflow on a user-provided Kubernetes
cluster, instead of running the workflow locally.</p>
<p>The result is <a href="https://github.com/charlesreid1/2019-snakemake-byok8s">2019-snakemake-byok8s</a>,
a command line utility that can be installed with
a <code>setup.py</code> and that launches a Snakemake workflow 
on a user-provided Kubernetes cluster. Furthermore,
we demonstrate how to use minikube to run a local
Kubernetes cluster to test Snakemake workflows on
Kubernetes clusters.</p>
<p>Here's what it looks like in practice:</p>
<div class="highlight"><pre><span></span># Get byok8s
git clone https://github.com/charlesreid1/2019-snakemake-byok8s.git
cd ~/2019-snakemake-byok8s

# Create a virtual environment
virtualenv vp
vp/bin/actiavte

# Install byok8s
pip install -r requirements.txt
python setup.py build install

# Create virtual k8s cluster
minikube start

# Run the workflow on the k8s cluster
cd /path/to/workflow/
byok8s my-workflowfile my-paramsfile --s3-bucket=my-bucket

# Clean up the virtual k8s cluster
minikube stop
</pre></div>


<p>We cover the details below.</p>
<h1 id="overview-of-2019-snakemake-byok8s">Overview of 2019-snakemake-byok8s</h1>
<h2 id="cloud-scale-kubernetes-k8s">Cloud + Scale = Kubernetes (k8s)</h2>
<p>First, why kubernetes (k8s)?</p>
<p>To scale Snakemake workflows to multiple compute nodes,
it is not enough to just give Snakemake a pile of
compute nodes and a way to remotely connect to each.
Snakemake requires the compute nodes to have a 
controller and a job submission system.</p>
<p>When using cloud computing platforms like GCP (Google 
Cloud Platform) or AWS (Amazon Web Services),
k8s is a simple and popular way to orchestrate
multiple compute nodes (support for Docker images
is also baked directly into k8s).</p>
<h2 id="snakemake-k8s-support">Snakemake k8s Support</h2>
<p>Snakemake has built-in support for k8s, making
the combination a logical choice for running 
Snakemake workflows at scale in the cloud. </p>
<p>The <code>minikube</code> tool, which we will cover later
in this blog post, makes it easy to run a local
virtual k8s cluster for testing purposes, and
even makes it possible to run k8s tests using
Travis CI.</p>
<p>Snakemake only requires the <code>--kubernetes</code> flag,
and an optional namespace, to connect to
the k8s cluster. (Under the hood, Snakemake
uses the Kubernetes Python API to connect
to the cluster and launch jobs.)</p>
<p>If you can run <code>kubectl</code> from a computer
to control the Kubernetes cluster, you can
run a Snakemake workflow on that cluster.</p>
<p>Let's get into the changes required in the Python code.</p>
<h1 id="modifying-the-cli">Modifying the CLI</h1>
<p>In our <a href="https://charlesreid1.github.io/building-snakemake-command-line-wrappers.html">prior post</a>
covering <a href="https://github.com/charlesreid1/2019-snakemake-cli">charlesreid1/2019-snakemake-cli</a>,
we showed how to create a command line utility
using the <code>cli/</code> directory for the command line
interface package, and specifying it is a cli
entrypoint in <code>setup.py</code>:</p>
<div class="highlight"><pre><span></span>cli/
├── Snakefile
├── __init__.py
└── command.py
</pre></div>


<p>and the relevant bit from <code>setup.py</code>:</p>
<div class="highlight"><pre><span></span><span class="n">setup</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;bananas&#39;</span><span class="p">,</span>
        <span class="o">...</span>
        <span class="n">entry_points</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">[console_scripts]</span>
<span class="si">{program}</span><span class="s2"> = cli.command:main</span>
<span class="s2">      &quot;&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">program</span> <span class="o">=</span> <span class="n">_program</span><span class="p">),</span>
</pre></div>


<p>We want our new command line utility, <code>byok8s</code>, to work
the same way, so we can do a <code>s/byok8s/bananas/g</code>
across the package.</p>
<p>The only change required happens in the file
<code>command.py</code>, where the Snakemake API call 
happens.</p>
<h2 id="namespaces">Namespaces</h2>
<p>Checking the <a href="https://snakemake.readthedocs.io/en/stable/api_reference/snakemake.html">Snakemake API documentation</a>,
we can see that the API has a <code>kubernetes</code> option:</p>
<blockquote>
<p><strong>kubernetes</strong> <em>(str)</em> – submit jobs to kubernetes,
using the given namespace.</p>
</blockquote>
<p>so <code>command.py</code> should modify the Snakmake API call
accordingly, adding a kubernetes namespace.
This is a parameter the user usually won't need
to provide (<code>default</code> is the typical namespace
we want to use) but we added a <code>-k</code> argument
to the ArgParser to allow the user to specify
the Kubernetes namespace name. By default
the Kubernetes namespace used is <code>default</code>.</p>
<h2 id="adding-flags">Adding flags</h2>
<p>We add and modify some flags to make the workflow
more flexible:</p>
<ul>
<li>
<p>The user now provides the Snakefile, which is
  called <code>Snakefile</code> in the current working directory
  by default but can be specified with the <code>--snakefile</code>
  or <code>-s</code> flag</p>
</li>
<li>
<p>The user provides the k8s namespace using the
  <code>--k8s-namespace</code> or <code>-k</code> flag</p>
</li>
<li>
<p>The user provides the name of an S3 bucket for
  Snakemake worker nodes to use for I/O using the
  <code>--s3-bucket</code> flag</p>
</li>
</ul>
<p>Finally, the user is also required to provide their
AWS credentials to access the S3 bucket, via two
environment variables that Snakemake passes through
to the Kubernetes worker nodes:</p>
<div class="highlight"><pre><span></span>AWS_ACCESS_KEY_ID
AWS_SECRET_ACCESS_KEY
</pre></div>


<p>For Travis CI testing, these environment variables
can be set in the repository settings on the Travis
website once Travis CI has been enabled.</p>
<p>See <a href="https://charlesreid1.github.io/2019-snakemake-byok8s/travis_tests/">https://charlesreid1.github.io/2019-snakemake-byok8s/travis_tests/</a>
for details.</p>
<h1 id="local-kubernetes-clusters-with-minikube">Local Kubernetes Clusters with Minikube</h1>
<h2 id="what-is-minikube">What is minikube?</h2>
<p>Minikube is a Go program that allows users to simulate
a single-node kubernetes cluster using a virtual machine.
This is useful for local testing of Kubernetes workflows,
as it does not require setting up or tearing down cloud
infrastructure, or long waits for remote resources to
become ready.</p>
<p>We cover two ways to use it:</p>
<ol>
<li>
<p>Installing and running a minikube virtual kubernetes cluster on
   AWS (for development and testing of Snakemake + kubernetes
   workflows)</p>
</li>
<li>
<p>Running a minikube cluster on a Travis CI worker node
   to enable us to <em>test</em> Snakemake + kubernetes workflows.</p>
</li>
</ol>
<h2 id="aws">AWS</h2>
<p>Using Minikube from an AWS EC2 compute node comes 
with two hangups.</p>
<p>The first is that AWS nodes are virtual machines,
and you can't run virtual machines within virtual
machines, so it is not possible to use minikube's
normal VirtualBox mode, which creates a kubernetes
cluster using a virutal machine.</p>
<p>Instead, we must use minikube's native driver, meaning
minikube uses docker directly. This is tricky for several
reasons:</p>
<ul>
<li>we can't bind-mount a local directory into the
  kubernetes cluster</li>
<li>the minikube cluster must be run with sudo
  privileges, which means permissions can be
  a problem</li>
</ul>
<p>The second hangup with minikube on AWS nodes is that the
DNS settings of AWS nodes are copied into the Kubernetes
containers, including the kubernetes system's DNS service
container. Unfortunately, the AWS node's DNS settings are
not valid in the kubernetes cluster, so the DNS container
crashes, and no container in the kubernetes cluster can
reach the outside world.  This must be fixed with a
custom config file (provided with byok8s; details below).</p>
<h3 id="installing-python-prerequisites">Installing Python Prerequisites</h3>
<p>To use byok8s from a fresh Ubuntu AWS node
(tested with Ubuntu 16.04 (xenial) and 18.04
(bionic)), you will want to install a version
of conda; we recommend using pyenv and miniconda:</p>
<div class="highlight"><pre><span></span>curl https://pyenv.run | bash
</pre></div>


<p>Restart your shell and install miniconda:</p>
<div class="highlight"><pre><span></span>pyenv update
pyenv install miniconda3-4.3.30
pyenv global miniconda3-4.3.30
</pre></div>


<p>You will also need the virtualenv package to
set up a virtual environment:</p>
<div class="highlight"><pre><span></span>pip install virtualenv
</pre></div>


<h3 id="installing-byok8s">Installing byok8s</h3>
<p>Start by cloning the repo and installing byok8s:</p>
<div class="highlight"><pre><span></span>cd 
git clone https://github.com/charlesreid1/2019-snakemake-byok8s.git
cd ~/2019-snakemake-byok8s
</pre></div>


<p>Next, you'll create a virtual environment:</p>
<div class="highlight"><pre><span></span>virtualenv vp
source vp/bin/activate

pip install -r requirements.txt
python setup.py build install
</pre></div>


<p>Now you should be ready to rock:</p>
<div class="highlight"><pre><span></span><span class="err">which byok8s</span>
</pre></div>


<h3 id="starting-a-k8s-cluster-with-minikube">Starting a k8s cluster with minikube</h3>
<p>Install minikube:</p>
<div class="highlight"><pre><span></span>curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \
  &amp;&amp; sudo install minikube-linux-amd64 /usr/local/bin/minikube
</pre></div>


<p>Now you're ready to start a minikube k8s
cluster on your AWS node! Start a k8s cluster
as root with:</p>
<div class="highlight"><pre><span></span>sudo minikube start
</pre></div>


<p><strong>NOTE:</strong> The <code>minikube start</code> command will print
some commands for you to run to fix permissions -
it is importat you run them!</p>
<p>Tear down the cluster with:</p>
<div class="highlight"><pre><span></span>sudo minikube stop
</pre></div>


<p>While the k8s cluster is running, you can control
it and interact with it like a normal k8s cluster
using <code>kubectl</code>.</p>
<p>However, as-is, the cluster's DNS settings are broken!
We need to fix them before running.</p>
<h2 id="fixing-dns-issues-with-aws">Fixing DNS issues with AWS</h2>
<p>We mentioned a second hangup with AWS was with the
DNS settings. </p>
<p>The problem is with <code>/etc/resolv.conf</code> on the
AWS host node. It is set up for AWS's internal 
cloud network routing, but this is copied
into the CoreDNS container, which is the
kube-system container that manages DNS requests
from all k8s containers. The settings from the
AWS host confuse the DNS container, and it cannot
route any DNS requests.</p>
<h3 id="the-problem">The Problem</h3>
<p>If you're having the problem, you will see
something like this with <code>kubectl</code>, where the
coredns containers are in a <code>CrashLoopBackOff</code>:</p>
<div class="highlight"><pre><span></span>$ kubectl get pods --namespace=kube-system

NAME                               READY   STATUS             RESTARTS   AGE
coredns-86c58d9df4-lvq8b           0/1     CrashLoopBackOff   5          5m17s
coredns-86c58d9df4-pr52t           0/1     CrashLoopBackOff   5          5m17s
etcd-minikube                      1/1     Running            15         4h43m
kube-addon-manager-minikube        1/1     Running            16         4h43m
kube-apiserver-minikube            1/1     Running            15         4h43m
kube-controller-manager-minikube   1/1     Running            15         4h43m
kube-proxy-sq77h                   1/1     Running            3          4h44m
kube-scheduler-minikube            1/1     Running            15         4h43m
storage-provisioner                1/1     Running            6          4h44m
</pre></div>


<p>This will cause all Snakemake jobs to fail with a name
resolution failure when it tries to write its output
files to the AWS S3 bucket:</p>
<div class="highlight"><pre><span></span>$ kubectl logs snakejob-c71fba38-f64b-5803-915d-933ae273d7a4

Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job counts:
    count   jobs
    1   target1
    1

[Thu Jan 24 00:06:03 2019]
rule target1:
    output: cmr-smk-0123/alpha.txt
    jobid: 0

echo alpha blue &gt; cmr-smk-0123/alpha.txt
Traceback (most recent call last):
  File &quot;/opt/conda/lib/python3.7/site-packages/urllib3/connection.py&quot;, line 171, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw)
  File &quot;/opt/conda/lib/python3.7/site-packages/urllib3/util/connection.py&quot;, line 56, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File &quot;/opt/conda/lib/python3.7/socket.py&quot;, line 748, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno -3] Temporary failure in name resolution
</pre></div>


<p>and the kubernetes log for the CoreDNS container</p>
<div class="highlight"><pre><span></span>$ kubectl logs --namespace=kube-system coredns-86c58d9df4-lvq8b

.:53
2019/01/25 14:54:48 [INFO] CoreDNS-1.2.2
2019/01/25 14:54:48 [INFO] linux/amd64, go1.11, fc62f9c
CoreDNS-1.2.2
linux/amd64, go1.11, eb51e8b
2019/01/25 14:54:48 [INFO] plugin/reload: Running configuration MD5 = 486384b491cef6cb69c1f57a02087373
2019/01/25 14:54:48 [FATAL] plugin/loop: Seen &quot;HINFO IN 9273194449250285441.798654804648663468.&quot; more than twice, loop detected
</pre></div>


<p>Basically, the AWS node's DNS name server settings cause 
an infinite DNS loop to be set up.</p>
<h3 id="the-fix">The Fix</h3>
<p>Fixing this problem requires manually setting the DNS 
name servers inside the CoreDNS container to Google's
public DNS servers, <code>8.8.8.8</code> and <code>8.8.4.4</code>.</p>
<p>To apply this fix, we use a YAML configuration file to patch the
CoreDNS container image.</p>
<p>Hat tip to <a href="https://github.com/kubernetes/minikube/issues/2027">this long Github issue</a>
in the minikube Github repo, and specifically 
<a href="https://github.com/kubernetes/minikube/issues/2027#issuecomment-381574807">this comment</a>
by Github user <a href="https://github.com/jgoclawski">jgoclawski</a>.
and also <a href="https://github.com/kubernetes/minikube/issues/2027#issuecomment-419733791">this comment</a>
by Github user <a href="https://github.com/bw2">bw2</a>.
(Note that neither of these quite solve the problem -
jgoclawski's solution is for kube-dns, not CoreDNS,
and bw2's YAML is not valid, but both got me most
of the way to a solution.)</p>
<p>Here is the YAML file (also in the 2019-snakemake-byok8s
repo here: <a href="https://github.com/charlesreid1/2019-snakemake-byok8s/blob/master/test/fixcoredns.yml">https://github.com/charlesreid1/2019-snakemake-byok8s/blob/master/test/fixcoredns.yml</a>):</p>
<p><strong><code>fixcoredns.yml</code>:</strong></p>
<div class="highlight"><pre><span></span><span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ConfigMap</span>
<span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">data</span><span class="p">:</span>
  <span class="nt">Corefile</span><span class="p">:</span> <span class="p p-Indicator">|</span>
    <span class="no">.:53 {</span>
        <span class="no">errors</span>
        <span class="no">health</span>
        <span class="no">kubernetes cluster.local in-addr.arpa ip6.arpa {</span>
           <span class="no">upstream 8.8.8.8 8.8.4.4</span>
           <span class="no">pods insecure</span>
           <span class="no">fallthrough in-addr.arpa ip6.arpa</span>
        <span class="no">}</span>
        <span class="no">proxy .  8.8.8.8 8.8.4.4</span>
        <span class="no">cache 30</span>
        <span class="no">reload</span>
    <span class="no">}</span>
<span class="nt">metadata</span><span class="p">:</span>
  <span class="nt">creationTimestamp</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2019-01-25T22:55:15Z</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">coredns</span>
  <span class="nt">namespace</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">kube-system</span>
</pre></div>


<p>(<strong>NOTE:</strong> There is also a <code>fixkubedns.yml</code> if you are using
an older Kubernetes version that uses kube-dns instead of
CoreDNS.)</p>
<p>To tell the k8s cluster to use this image
when it creates a CoreDNS container, run
this kubectl command <em>while the cluster is
running</em>:</p>
<div class="highlight"><pre><span></span>kubectl apply -f fixcoredns.yml
</pre></div>


<p>Last but not least, delete all <code>kube-system</code> containers
and let Kubernetes regenerate them:</p>
<div class="highlight"><pre><span></span>kubectl delete --all pods --namespace kube-system
</pre></div>


<p>The pods will regenerate quickly, and you can
check to confirm that the CoreDNS container
is no longer in the <code>CrashLoopBackOff</code> state
and is <code>Running</code> nicely:</p>
<div class="highlight"><pre><span></span>kubectl get pods --namespace=kube-system
</pre></div>


<p>This is all documented in <a href="https://github.com/kubernetes/minikube/issues/2027#issuecomment-457808462">this comment</a>
in the same Github issue in the minikube repo
that was linked to above, <a href="https://github.com/kubernetes/minikube/issues/2027">kubernetes/minikube
issue #2027: dnsmasq pod CrashLoopBackOff</a>.</p>
<h2 id="aws-byok8s-workflow">AWS + byok8s Workflow</h2>
<p>Now that the k8s cluster is running successfully,
run the example byok8s workflow in the <code>test/</code> 
directory of the byok8s repository (assuming
you cloned the repo to <code>~/byok8s</code>, and are in
the same virtual environment as before):</p>
<div class="highlight"><pre><span></span># Return to our virtual environment
cd ~/2019-snakemake-byok8s/test/
source vp/bin/activate

# Verify k8s is running
minikube status

# Export AWS keys for Snakemake
export AWS_ACCESS_KEY_ID=&quot;XXXXX&quot;
export AWS_SECRET_ACCESS_KEY=&quot;XXXXX&quot;

# Run byok8s
byok8s workflow-alpha params-blue --s3-bucket=mah-bukkit 
</pre></div>


<p>The bucket you specify must be created in advance
and be writable by the account whose credentials
you are passing in via environment variables.</p>
<p>When you do all of this, you should see the job
running, then exiting successfully:</p>
<div class="highlight"><pre><span></span>$ byok8s --s3-bucket=cmr-0123 -f workflow-alpha params-blue
--------
details!
    snakefile: /home/ubuntu/2019-snakemake-byok8s/test/Snakefile
    config: /home/ubuntu/2019-snakemake-byok8s/test/workflow-alpha.json
    params: /home/ubuntu/2019-snakemake-byok8s/test/params-blue.json
    target: target1
    k8s namespace: default
--------
Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
    count   jobs
    1   target1
    1
Resources before job selection: {&#39;_cores&#39;: 1, &#39;_nodes&#39;: 9223372036854775807}
Ready jobs (1):
    target1
Selected jobs (1):
    target1
Resources after job selection: {&#39;_cores&#39;: 0, &#39;_nodes&#39;: 9223372036854775806}

[Mon Jan 28 18:06:08 2019]
rule target1:
    output: cmr-0123/alpha.txt
    jobid: 0

echo alpha blue &gt; cmr-0123/alpha.txt
Get status with:
kubectl describe pod snakejob-e585b53f-f9d5-5142-ac50-af5a0d532e85
kubectl logs snakejob-e585b53f-f9d5-5142-ac50-af5a0d532e85
Checking status for pod snakejob-e585b53f-f9d5-5142-ac50-af5a0d532e85
[Mon Jan 28 18:06:18 2019]
Finished job 0.
1 of 1 steps (100%) done
Complete log: /home/ubuntu/2019-snakemake-byok8s/test/.snakemake/log/2019-01-28T180607.988313.snakemake.log
unlocking
removing lock
removing lock
removed all locks
</pre></div>


<p>Woo hoo! You've successfully run a Snakemake workflow 
on a virtual Kubernetes cluster!</p>
<h2 id="travis">Travis</h2>
<p>Like running minikube on an AWS node, running minikube on Travis workers
also suffers from DNS issues. Fortunately, Github user 
<a href="https://github.com/LiliC">LiliC</a> worked out how to run
minikube on Travis, and importantly, <em>did so for multiple versions</em>
of minikube and kubernetes.</p>
<p>The relevant <code>.travis.yml</code> file is available in the 
<a href="https://github.com/LiliC/travis-minikube">LiliC/travis-minikube</a>
repo on Github.</p>
<p>We ended up using the <a href="https://github.com/LiliC/travis-minikube/tree/minikube-30-kube-1.12"><code>minikube-30-kube-1.12</code></a>
branch of LiliC/travis-minikube, which used the most up-to-date
version of minikube and kubernetes available in that repo. The <code>.travis.yml</code> file
provided by LiliC on that branch is 
<a href="https://github.com/LiliC/travis-minikube/blob/minikube-30-kube-1.12/.travis.yml">here</a>.</p>
<p>The example script by LiliC provided 90% of the legwork (thanks!!!),
and we only needed to modify a few lines of LiliC's Travis file
(which launches a redis container using kubectl)
to use Snakemake (launched via byok8s) instead.</p>
<h2 id="travisyml"><code>.travis.yml</code></h2>
<p>Here is the final <code>.travis.yml</code> file, which has explanatory comments.</p>
<p><strong><code>.travis.yml</code>:</strong></p>
<div class="highlight"><pre><span></span><span class="c1"># Modified from original:</span>
<span class="c1"># https://raw.githubusercontent.com/LiliC/travis-minikube/minikube-30-kube-1.12/.travis.yml</span>

<span class="c1"># byok8s and Snakemake both require Python,</span>
<span class="c1"># so we make this Travis CI test Python-based.</span>
<span class="nt">language</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">python</span>
<span class="nt">python</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="s">&quot;3.6&quot;</span>

<span class="c1"># Running minikube via travis requires sudo</span>
<span class="nt">sudo</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">required</span>

<span class="c1"># We need the systemd for the kubeadm and it&#39;s default from 16.04+</span>
<span class="nt">dist</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">xenial</span>

<span class="c1"># This moves Kubernetes specific config files.</span>
<span class="nt">env</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">CHANGE_MINIKUBE_NONE_USER=true</span>

<span class="nt">install</span><span class="p">:</span>
<span class="c1"># Install byok8s requirements (snakemake, python-kubernetes)</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">pip install -r requirements.txt</span>
<span class="c1"># Install byok8s cli tool</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">python setup.py build install</span>

<span class="nt">before_script</span><span class="p">:</span>
<span class="c1"># Do everything from test/</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">cd test</span>
<span class="c1"># Make root mounted as rshared to fix kube-dns issues.</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">sudo mount --make-rshared /</span>
<span class="c1"># Download kubectl, which is a requirement for using minikube.</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">curl -Lo kubectl https://storage.googleapis.com/kubernetes-release/release/v1.12.0/bin/linux/amd64/kubectl &amp;&amp; chmod +x kubectl &amp;&amp; sudo mv kubectl /usr/local/bin/</span>
<span class="c1"># Download minikube.</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.30.0/minikube-linux-amd64 &amp;&amp; chmod +x minikube &amp;&amp; sudo mv minikube /usr/local/bin/</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">sudo minikube start --vm-driver=none --bootstrapper=kubeadm --kubernetes-version=v1.12.0</span>
<span class="c1"># Fix the kubectl context, as it&#39;s often stale.</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">minikube update-context</span>
<span class="c1"># Wait for Kubernetes to be up and ready.</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">JSONPATH=&#39;{range .items[*]}{@.metadata.name}:{range @.status.conditions[*]}{@.type}={@.status};{end}{end}&#39;; until kubectl get nodes -o jsonpath=&quot;$JSONPATH&quot; 2&gt;&amp;1 | grep -q &quot;Ready=True&quot;; do sleep 1; done</span>

<span class="c1">################</span>
<span class="c1">## easy test</span>
<span class="nt">script</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">kubectl cluster-info</span>
<span class="c1"># Verify kube-addon-manager.</span>
<span class="c1"># kube-addon-manager is responsible for managing other kubernetes components, such as kube-dns, dashboard, storage-provisioner..</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">JSONPATH=&#39;{range .items[*]}{@.metadata.name}:{range @.status.conditions[*]}{@.type}={@.status};{end}{end}&#39;; until kubectl -n kube-system get pods -lcomponent=kube-addon-manager -o jsonpath=&quot;$JSONPATH&quot; 2&gt;&amp;1 | grep -q &quot;Ready=True&quot;; do sleep 1;echo &quot;waiting for kube-addon-manager to be available&quot;; kubectl get pods --all-namespaces; done</span>
<span class="c1"># Wait for kube-dns to be ready.</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">JSONPATH=&#39;{range .items[*]}{@.metadata.name}:{range @.status.conditions[*]}{@.type}={@.status};{end}{end}&#39;; until kubectl -n kube-system get pods -lk8s-app=kube-dns -o jsonpath=&quot;$JSONPATH&quot; 2&gt;&amp;1 | grep -q &quot;Ready=True&quot;; do sleep 1;echo &quot;waiting for kube-dns to be available&quot;; kubectl get pods --all-namespaces; done</span>

<span class="c1">################ </span>
<span class="c1">## hard test</span>
<span class="c1"># run byok8s workflow on the k8s cluster</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">byok8s --s3-bucket=cmr-0123 -f workflow-alpha params-blue</span>
</pre></div>


<h1 id="end-product-byok8s">End Product: byok8s</h1>
<p>The final byok8s package can be found in the
<a href="https://github.com/charlesreid1/2019-snakemake-byok8s">charlesreid1/2019-snakemake-byok8s</a>
repository on Github.</p>
<p>You can find documentation for 2019-snakemake-byok8s 
here: <a href="https://charlesreid1.github.io/2019-snakemake-byok8s/">https://charlesreid1.github.io/2019-snakemake-byok8s/</a></p>
<p>To return to our quick start, here is what running
byok8s end-to-end on a minikube kubernetes cluster 
on an AWS node looks like (slightly modified from
the intro of our post):</p>
<div class="highlight"><pre><span></span># Install minikube
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \
  &amp;&amp; sudo install minikube-linux-amd64 /usr/local/bin/minikube

# Get byok8s
git clone https://github.com/charlesreid1/2019-snakemake-byok8s.git
cd ~/2019-snakemake-byok8s

# Create a virtual environment
virtualenv vp
vp/bin/actiavte

# Install byok8s
pip install -r requirements.txt
python setup.py build install

# Create virtual k8s cluster
sudo minikube start

# Fix CoreDNS
kubectl apply -f fixcoredns.yml
kubectl delete --all pods --namespace kube-system

# Wait for kube-system to respawn
kubectl get pods --namespace=kube-system

# Run the workflow on the k8s cluster
cd test/
byok8s workflow-alpha params-blue --s3-bucket=mah-bukkit 

# Clean up the virtual k8s cluster
sudo minikube stop
</pre></div>


<h1 id="documentation">Documentation</h1>
<p>You can find documentation for 2019-snakemake-byok8s 
here: <a href="https://charlesreid1.github.io/2019-snakemake-byok8s/">https://charlesreid1.github.io/2019-snakemake-byok8s/</a></p>
<p>The documentation covers a quick start on AWS nodes, 
similar to what is covered above, as well as more information
about running byok8s on other types of Kubernetes clusters
(e.g., AWS, Google Cloud, and Digital Ocean).</p>
<h1 id="next-steps">Next Steps</h1>
<p>Last year we were working on implementing metagenomic pipelines for
shotgun sequencing data as part of the <a href="https://github.com/dahak-metagenomics">dahak-metagenomics</a>
project. We implemented several Snakemake workflows
in the <a href="https://github.com/dahak-metagenomics/dahak">dahak</a>
repo, and began (but never completed) work on a command line utility
to run these workflows called <a href="https://github.com/dahak-metagenomics/dahak-taco">dahak-taco</a>.</p>
<p>Our next major goal is to reboot dahak-taco and redesign it to run metagenomic
workflows from dahak on Kubernetes clusters, similar to the way byok8s works.</p>
<p>Stay tuned for more!</p></div>

    </div>
</div>

<div class="v20"></div>

<div class="row">
    <div class="col-md-12" style="text-align: left;">

        <div class="tags">
            <p>Tags:&nbsp;&nbsp;&nbsp;
                    <a href="http://localhost:8000/tag/python.html">python</a>
                    &nbsp;&nbsp;
                    <a href="http://localhost:8000/tag/bioinformatics.html">bioinformatics</a>
                    &nbsp;&nbsp;
                    <a href="http://localhost:8000/tag/workflows.html">workflows</a>
                    &nbsp;&nbsp;
                    <a href="http://localhost:8000/tag/pipelines.html">pipelines</a>
                    &nbsp;&nbsp;
                    <a href="http://localhost:8000/tag/snakemake.html">snakemake</a>
                    &nbsp;&nbsp;
                    <a href="http://localhost:8000/tag/travis.html">travis</a>
                    &nbsp;&nbsp;
                    <a href="http://localhost:8000/tag/kubernetes.html">kubernetes</a>
                    &nbsp;&nbsp;
                    <a href="http://localhost:8000/tag/minikube.html">minikube</a>
                    &nbsp;&nbsp;
        </div>

    </div>
</div>


<div class="v200"></div>

</div>


<script type="text/javascript" src="http://localhost:8000/theme/js/jquery-1.11.2.js"></script>
<script type="text/javascript" src="http://localhost:8000/theme/js/bootstrap-3.3.4.js"></script>
<script type="text/javascript" src="http://localhost:8000/theme/js/d3-3.5.5.js"></script><script type="text/javascript" src="http://localhost:8000/theme/js/jquery-1.11.2.js"></script>
<script type="text/javascript" src="http://localhost:8000/theme/js/bootstrap-3.3.4.js"></script>

<footer id="contentinfo" class="body">
<p>&nbsp;</p>
<p>&nbsp;</p>
<center>
	<hr />
</center>
<p>&nbsp;</p>
<p style="text-align: center">
    <span class="fa-stack fa-lg">
        <i class="fa fa-square fa-stack-2x" style="color:#000;"></i>
        <i class="fa fa-terminal fa-stack-1x fa-inverse"></i>
    </span>
    Made from the command line with vim by 
    <a href="http://charlesreid1.com">charlesreid1</a><br />
    with help from <a href="https://getbootstrap.com/">Bootstrap</a> and <a href="http://getpelican.com">Pelican</a>.
</p>

<br />

<p style="text-align: center">
    <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">
    <span class="fa-stack fa-lg">
        <i class="fa fa-square fa-stack-2x" style="color:#000;"></i>
        <i class="fa fa-creative-commons fa-stack-1x fa-inverse"></i>
    </span>
    </a>
    <br />
    Licensed under the <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">Creative Commons Attribution-NonCommercial 4.0 License</a>.
</p>

<!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=11611748;
var sc_invisible=1;
var sc_security="9fcba820";
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>

<noscript><div class="statcounter"><a title="Web Analytics"
href="http://statcounter.com/" target="_blank"><img
class="statcounter"
src="//c.statcounter.com/11611748/0/9fcba820/1/" alt="Web
Analytics"></a></div></noscript>
<!-- End of StatCounter Code for Default Guide -->
</footer><!-- /#contentinfo -->
</body>
</html>